---
title: |
  | Reducing Corruption through Legislative Action
  | \LARGE A study of the Indian \textsl{Janlokpal Bill (2013)} 
author: "Devvart Poddar"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    fig_width: 4
    fig_height: 4
    highlight: tango
    keep_tex: yes
    number_sections: yes
    toc: yes
    includes:
      in_header: templates/header.tex
bibliography: Bibtex.bib
classoption: twoside
csl: templates/apa.csl
---

\pagebreak

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/home/devvart/Desktop/CorruptionInIndia/")
knitr::opts_chunk$set(dev = 'pdf',
                      fig.pos = 'H')

rm(list = ls())
pkgs <- c("dplyr", "magrittr", "methods", "rvest", "stringi", "rio", "ggplot2",
  "tm", "wordcloud", "viridis", "pdftools", "xml2", "lubridate", "stargazer", "knitr",  "plm", "koRpus")

load <- sapply(pkgs, function(x) {
	suppressPackageStartupMessages(
  	require(x, character.only = TRUE)
	)
  }
)
rm(load, pkgs)
```

# Introduction

Corruption has become a major flash point in the Indian political debate post multiple scandals which rocked India in 2011. A major policy issue at the height of the debate was the creation of an independent corruption watchdog through legislative assent; the *Jan Lokpal Act* of 2013. The watchdog itself was recommended as far back as 1969, but was never created in the fluid political scenario.

There have been several studies which have looked at the impact of legislative actions in reducing corruption [See @quah2007combating, @prado2016brazilian], however the results of the reforms are mixed. While Singapore was successful in the enforcement of their reforms in the city-state, similar changes in Brazil failed to reduce corruption. Moreover the study of corruption, be definition, is difficult to measure. Corruption is undertaken in the shadows of economic and political actions, and is notoriously difficult to predict. Watchdogs like the Transparency International (TI) use perception surveys which are conducted wig *experts* around the work. Other NGOs in India like the Center for Media Studies (CMS) also measure corruption through surveys, albeit with citizens across the country.

However, there are several issues which plague expert surveys. They are a subjective measure of perception which may be impacted by Individual biases. As the same individual is not studied across her lifetime, it is hard to dis aggregate the idiosyncratic biases from actual corruption. Thus I turn to the use of Indian media data sets to create an unbiased indicator of corruption.

# Methodolgy

## Media as Data

This study is not the first to use media as a source of data for economic research. @jansen2005talking use media to identify the impact of communications from the European Central Bank (ECB) on exchange rate volatility. Similarly @baker2015measuring use media data to identify and measure economic policy uncertainty in 15 countries. However to the best of the author's knowledge, no study has used media as an indicator for corruption.

For the study, nearly 19000 articles were scrapped from [Google News]("https://news.google.com/") for a period of 8 years; from 2008 ~ 2016. The frequency of the articles is showcased in Figure 1 below. They identify two main changes in the approach of the study; *firstly* due to idiosyncrasies of Google News, there is a jump in the number of articles on corruption for the last month of the study. This is a clear outlive, possibly due to sorting on the basis of the time of the scraping. Those months will be ignored in the analysis.

*Secondly* we see a clear time trend and a seasonal component to the number of articles. While the time trend was expected, as the news media has evolved rapidly to growing digitization, the seasonal trend was not expected. Regardless moving forward, the study will take into account the time trend and seasonality in all further analysis. 

``` {r freqplot, echo = FALSE, message = FALSE, warning = FALSE, fig.cap = "Trend in articles on corruption in India", cache = 2}

# Function for splitting
date.split <- function(text, x) {
  text.split <- stri_split_fixed(text, " ") %>%
    unlist() %>% .[x]
  
  return(text.split)
}

load.data <- import("Output/processed/web-text.json") %>%
  filter(!is.na(text)) %>%
  filter(!grepl("No text availlable", text)) %>%
  mutate(Year = NA, Month = NA, date = NA)

for (x in 1:nrow(load.data)) {
  Date <- load.data$Date[x]
  
  load.data$Year[x] <- date.split(Date, 3) %>% as.numeric()
  
  load.data$Month[x] <- date.split(Date, 2) %>% match(month.abb)
  
}

load.data %<>% 
  select(-Date) %>%
  mutate(total = nrow(.)) %>%
  group_by(Year, Month) %>%
  dplyr::summarise(freq = n(), total = mean(total)) %>%
  ungroup() %>%
  filter(Year >= 2008) %>%
  mutate(date = as.Date(paste(Year, Month, "01", sep = "-")))

ggplot(load.data) +
  geom_line(aes(x = date, y = freq / total, group = 1)) +
  scale_color_viridis() +
  labs(y = "% of Articles", x = "Year") +
  scale_x_date(date_breaks = "1 years", date_labels = "%Y") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()

```

## Insights from Text

The media data sets are incredibly insightful in terms of the richness of the data provided. We can measure corruption up-till the states, and even cities to a certain extent. The wealth of data also allows analysis of the different aspects of corruption itself, i.e. the forms of corruption. We can also track the growth in corruption by different groups (corporate houses, politicians, NGOs etc) separately. However those are beyond the scope of this research. For the study, we will create a indicator of corruption using text, for the different states in India.  

### Lemmatisation and Natural Language Programming

The first stage of the analysis involves the use of **Treetagger**, a tool developed by @schmid1994treetagger for annotating text with part-of-speech tags. **Treetagger** can annotate over 13 languages, and provides us with the *lemma*, the root form of a word. Lemmatisation is a powerful method of reducing the complexity of text, particularly in form of the different tenses, without changing the meaning of the text. The lemmatisation is further restricted on adjectives and adverbs, i.e. any word that qualifies / describes the context of the article is not modified. This would help in the succeeding stages to help create an index of corruption.

The text is also cleaned using a Natural Language Programming (NLP) framework [See @manning1999foundations for a definative guide to NLP]. Natral Language Programming in an intersection of comupational-linuistics and artificial intelligence, aiming to make text *machine-readable*. As such, it is the base of all systems that depend upon understanding and analysing text (Siri from Apple is one of the best examples. The core component of Siri, understanding the *human* command, works through applications of NLP. See @Dworetzky).

For the study, NLP is used primarly to detect *negation* and *emphasis*. Thus words like *not* and *no* which invert the meaning of a sentence are taken into account when building the index, as well as emphasis words like *very* and *greatly* which increase the emphasis of the sentence. Moreover the indicator is built at a sentence level, i.e we do not look at the entire text, but a window of words around corruption. This allows the index to identify the rising and falling trends of corruption in the different states.

To better understand the techniques of lemmatisation, and how it helps in creating the index, a small example is given below. The following quote is taken from a article on corruption against a prominent Indian politician; 

> *One of India's most colourful and controversial politicians, Jayaram Jayalalitha, has been sentenced to jail for four years on corruption charges in a case that has lasted for 18 years. The chief minister of the southern state of Tamil Nadu was found guilty of amassing wealth of more than $10m (£6.1m) which was unaccounted for. She has to pay a 1bn rupee ($16m; £10m) fine and resign as chief minister.* (@bbc2014)

Upon cleaning and lemmatising, the text will change to as below;

``` {r lemmademo, echo = FALSE, message = FALSE, warning = FALSE, results = "asis"}
text.clean <- function(text) {
  text <- as.character(text)

  # Defining extra words
  extra.words <- c("united", "states", "america", "pdf", "ferc", "m")

  # Removing stop words, punctation, numbers, special charcters and whitespace
  text %<>%
    stri_replace_all_regex("[[:punct:]]|\\$|\\+|\\£", "") %>%
    stri_replace_all_regex("\\s+", " ") %>%
    VectorSource() %>%
    VCorpus() %>%
    tm_map(content_transformer(tolower)) %>%
    tm_map(removeNumbers) %>%
    tm_map(removeWords, stopwords()) %>%
    tm_map(removeWords, extra.words) %>%
    # sapply(`[`, "content") %>%
    sapply(as.character)

  return(text)
}

# Lemmatising text to convert to tokens
text.lemma <- function(text) {
  text <- as.character(text) %>%
    tolower()

  # Create a lemma dataframe of the text
  ## Creating a temporary file
  file.con <- file("temp.txt")
  writeLines(text, file.con)
  close(file.con)

  # Creating temporary dataframe with lemma
  temp.data <- treetag("temp.txt",
    treetagger = "manual",
    lang = "en",
    TT.options = list(
      path = "/home/devvart/treetagger",
      preset = "en"
      ))

  temp.data <- temp.data@TT.res %>%
    select(token, lemma) %>%
    mutate(
      lemma = ifelse(lemma == "<unknown>", token, lemma)
      )

  file.remove("temp.txt")

  # Replacing words with their lemma
  for (x in 1:nrow(temp.data)) {
    # Values
    token <- paste0("\\b", temp.data$token[x], "\\b")
    # token <- temp.data$token[x]
    lemma <- temp.data$lemma[x]

    # Replacing
    error <- try(text %<>% stri_replace_all_regex(token, lemma))

    if (inherits(error, "try-error")) {
      message.text <- paste0(token, " ----- ", lemma)
      message(message.text)
      stop("Stopping cleaning until error resolves")
    }
  }

  # Removing text spaces
  text %<>% stri_replace_all_regex("\\s+", " ")

  return(text)
}

text <- "One of India's most colourful and controversial politicians, Jayaram Jayalalitha, has been sentenced to jail for four years on corruption charges in a case that has lasted for 18 years. The chief minister of the southern state of Tamil Nadu was found guilty of amassing wealth of more than $10m (£6.1m) which was unaccounted for. She has to pay a 1bn rupee ($16m; £10m) fine and resign as chief minister"

new_text <- text %>%
  text.clean() %>%
  text.lemma()

format_text <- paste0("> *", new_text, "* ")

cat(format_text)
```

### States and corruption

## Regression Framework

# Results

# Conclusions

# References
